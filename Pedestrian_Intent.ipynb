{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNEu1Bz2BUbJH67tzGN30ZY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pratimamau/PID/blob/main/Pedestrian_Intent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P82Os7Yb3lkx"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Pratimamau/PID"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run this to access the weight files from the drive link shared \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tmKi_1e_4ARV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run this\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import glob\n",
        "\n",
        "%cd PID\n",
        " \n",
        "import sys #Run this\n",
        "from absl import app, logging, flags\n",
        "from absl.flags import FLAGS\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from yolov3_tf2.models import (\n",
        "    YoloV3, YoloV3Tiny\n",
        ")\n",
        "from yolov3_tf2.dataset import transform_images, load_tfrecord_dataset\n",
        "from yolov3_tf2.utils import draw_outputs\n",
        "\n",
        "%cd /content/PID/deep_sort\n",
        "from ds_tools.generate_detections import create_box_encoder\n",
        "from ds_application_util import preprocessing\n",
        "from ds_deep_sort import nn_matching\n",
        "from ds_deep_sort.detection import Detection\n",
        "from ds_deep_sort.tracker import Tracker\n",
        "\n",
        "%cd /content/PID\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "flags.DEFINE_string('classes', 'data/coco.names', 'path to classes file')\n",
        "flags.DEFINE_string('weights', '/content/drive/My Drive/datax_volvo_additional_files/yolov3_train_5.tf','path to weights file')\n",
        "flags.DEFINE_boolean('tiny', False, 'yolov3 or yolov3-tiny')\n",
        "flags.DEFINE_integer('size', 416, 'resize images to')\n",
        "flags.DEFINE_string('tfrecord', None, 'tfrecord instead of image')\n",
        "flags.DEFINE_integer('num_classes', 1, 'number of classes in the model')\n",
        "flags.DEFINE_string('video', 'data/video_0016.mp4','path to video file or number for webcam)')\n",
        "flags.DEFINE_string('output','Result_model_B.mp4', 'path to output video')\n",
        "flags.DEFINE_string('output_format', 'mp4v', 'codec used in VideoWriter when saving video to file')\n",
        "\n",
        "app._run_init(['yolov3'], app.parse_flags_with_usage)\n",
        "\n",
        "with open('densenet_model.json', 'r') as json_file:\n",
        "    json_savedModel= json_file.read()\n",
        "\n",
        "model_j = tf.keras.models.model_from_json(json_savedModel)\n",
        "model_j.load_weights('densenet_1.hdf5')\n",
        "\n",
        "def pred_func(X_test):\n",
        "  predictions = model_j.predict(X_test[0:1], verbose=0)\n",
        "  Y = np.argmax(predictions[0], axis=0)\n",
        "    \n",
        "  return Y"
      ],
      "metadata": {
        "id": "e6jVJd5D4Q1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters for DeepSORT the object tracker\n",
        "import csv\n",
        "nms_max_overlap = 1.0\n",
        "max_cosine_distance = 0.2\n",
        "nn_budget = None\n",
        "\n",
        "# DeepSORT initialization\n",
        "encoder = create_box_encoder('mars-small128.pb', batch_size=32)\n",
        "metric = nn_matching.NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n",
        "tracker = Tracker(metric)\n",
        "\n",
        "# Yolo initialization\n",
        "FLAGS.yolo_iou_threshold = 0.5\n",
        "FLAGS.yolo_score_threshold = 0.5\n",
        "\n",
        "yolo = YoloV3(classes=FLAGS.num_classes)\n",
        "yolo.load_weights(FLAGS.weights).expect_partial()\n",
        "\n",
        "class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\n",
        "\n",
        "resize_out_ratio = 4.0\n",
        "fps_time = 0\n",
        "\n",
        "def run_model():\n",
        "  print('Processing started.......')\n",
        "  try:\n",
        "      vid = cv2.VideoCapture(int(FLAGS.video))\n",
        "  except:\n",
        "      vid = cv2.VideoCapture(FLAGS.video)\n",
        "\n",
        "  out = None\n",
        "\n",
        "  if FLAGS.output:\n",
        "      # by default VideoCapture returns float instead of int\n",
        "      width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "      height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "      fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
        "      codec = cv2.VideoWriter_fourcc(*FLAGS.output_format)\n",
        "      out = cv2.VideoWriter(FLAGS.output, codec, fps, (width, height))\n",
        "\n",
        "  frame = 0\n",
        "  rolling_data={}\n",
        "  fps_time=0\n",
        "  result=[]\n",
        "\n",
        "  csv_file = \"pedestrian_data.csv\"\n",
        "  header = [\"Frame Number\", \"Pedestrian ID\", \"BCoordinates x\", \"BCoordinates y\", \"BCoordinates wx\", \"BCoordinates hy\",\"Pedestrian Intent\"]\n",
        "  data_dict={}\n",
        "  while True:\n",
        "\n",
        "    _, img = vid.read() # reading the image\n",
        "\n",
        "    if img is None:\n",
        "        break\n",
        "        logging.warning(\"Empty Frame\")\n",
        "        time.sleep(0.1)\n",
        "        continue\n",
        "    frame += 1   \n",
        "    currFrame = int(vid.get(cv2.CAP_PROP_POS_FRAMES))\n",
        "    fps = vid.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "\n",
        "    img_in = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n",
        "    img_orig = np.copy(img_in)\n",
        "    img_in = tf.expand_dims(img_in, 0)\n",
        "    img_in = transform_images(img_in, FLAGS.size)\n",
        "\n",
        "    boxes, scores, classes, nums = yolo.predict(img_in, steps=1) # yolo\n",
        "    boxes = boxes[:,:nums[0],:].reshape(nums[0], 4)[classes[0][:nums[0]] == 0]\n",
        "    scores = scores[0][:nums[0]][classes[0][:nums[0]] == 0]\n",
        "    nums = len(boxes)\n",
        "\n",
        "    # converting [x1,y1,x2,y2] -> [x1,y1,w,h] for bboxes detected\n",
        "    wh = np.flip(img.shape[0:2])\n",
        "    bbtlwh = []\n",
        "    for i in range(nums):\n",
        "\n",
        "      x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))\n",
        "      x1 = x1y1[0]\n",
        "      y1 = x1y1[1]\n",
        "      x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))\n",
        "      bbwh = (x2y2[0]-x1y1[0], x2y2[1]-x1y1[1])\n",
        "      w = bbwh[0]\n",
        "      h = bbwh[1]\n",
        "      bbtlwh.append([x1,y1,w,h])\n",
        "\n",
        "    features = encoder(img, bbtlwh) # deepsort input\n",
        "    detections = [Detection(box, conf, feat) for box, conf, feat in zip(bbtlwh, scores, features)] #deep sort output \n",
        "\n",
        "    # Update tracker.\n",
        "    tracker.predict()\n",
        "    tracker.update(detections)\n",
        "    \n",
        "    tracked_bbox = []\n",
        "    ids = []\n",
        "\n",
        "    for track in tracker.tracks:\n",
        "\n",
        "      if not track.is_confirmed() or track.time_since_update > 1:\n",
        "        continue\n",
        "      tracked_bbox.append(track.to_tlwh())\n",
        "      ids.append(track.track_id)\n",
        "\n",
        "    x_array = []\n",
        "    y_array = []\n",
        "    w_array = []\n",
        "    h_array = []\n",
        "    intent_array = []\n",
        "\n",
        "    for i in range(len(tracked_bbox)): # densenet \n",
        "\n",
        "      # Show tracker output\n",
        "      x, y, w, h = tracked_bbox[i]\n",
        "      x = int(x)  \n",
        "      y = int(y)\n",
        "      w = int(w) \n",
        "      h = int(h) \n",
        "\n",
        "      x_array.append(x)\n",
        "      y_array.append(y)\n",
        "      w_array.append(w+x)\n",
        "      h_array.append(h+y)\n",
        "\n",
        "      # looking for previous 16 frames data for a given pedestrian:\n",
        "\n",
        "      intent = 0 #(default, the pedestrian is not crossing)\n",
        "\n",
        "      \n",
        "      if int(ids[i]) in list(rolling_data.keys()):\n",
        "\n",
        "        if len(rolling_data[int(ids[i])]) == 16:\n",
        "          \n",
        "          seq = np.stack(np.array(rolling_data[int(ids[i])]),axis=2)\n",
        "          seq = np.expand_dims(seq, axis=0)\n",
        "          intent = pred_func(seq) # classification output\n",
        "\n",
        "        else:\n",
        "\n",
        "          seq = np.stack(np.array([rolling_data[int(ids[i])][-1]] * 16),axis=2)\n",
        "          seq = np.expand_dims(seq, axis=0)\n",
        "          intent = pred_func(seq) # classification output\n",
        "\n",
        "      # risky pedestrian identification thru box color\n",
        "      intent_array.append(intent)\n",
        "\n",
        "      if intent == 1:\n",
        "        color = (0, 0, 255) # Red -> Crossing\n",
        "\n",
        "      else:\n",
        "        color = (0, 255, 0) # green -> Not crossing\n",
        "\n",
        "      fps_time = time.time()\n",
        "      #color = (0, 255, 0)\n",
        "      img = cv2.rectangle(img, (int(x), int(y)), (int(x + w), int(y + h)), color, 2)\n",
        "      img = cv2.putText(img, 'TrackID ' + str(ids[i]), (x, y - 5), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 0, 0), thickness=2)\n",
        "      img = cv2.putText(img,\"Frame No: %d\" % (frame),(10, 10),  cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0, 0, 255), 2)\n",
        "      result.append([frame, str(ids), str(x_array), str(y_array), str(w_array),str(h_array), str(intent_array)])\n",
        "      print(result)\n",
        "\n",
        "      \n",
        "\n",
        "      # Loop through each row of data\n",
        "      for row in result:\n",
        "        label = row[0]\n",
        "    \n",
        "      # Update the dictionary with the current row of data for the given label\n",
        "      data_dict[label] = row\n",
        "\n",
        "\n",
        "\n",
        "      with open(csv_file, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(header)\n",
        "\n",
        "        # Write each row of data to the CSV file\n",
        "        for label in sorted(data_dict.keys()):\n",
        "          writer.writerow(data_dict[label])\n",
        "        # for row in result:\n",
        "        #   writer.writerow(row)\n",
        "\n",
        "      # storing the data for last 16 frames\n",
        "      try:\n",
        "\n",
        "        if int(ids[i]) in list(rolling_data.keys()): # ID exists in dict\n",
        "\n",
        "          if len(rolling_data[int(ids[i])]) < 16: # bboxes values for 16 frames\n",
        "              \n",
        "            cropped_seq = []\n",
        "            cropped_img = cv2.resize(img_orig[y:h+y, x:w+x],(100,100))\n",
        "            rolling_data[int(ids[i])].append(np.asarray(cropped_img)) # append the image      \n",
        "\n",
        "          else:\n",
        "\n",
        "            del rolling_data[int(ids[i])][0] # delete oldest frame bbox and append latest frame bbox\n",
        "            cropped_seq = []\n",
        "            cropped_img = cv2.resize(img_orig[y:h+y, x:w+x],(100,100))\n",
        "            rolling_data[int(ids[i])].append(np.asarray(cropped_img))\n",
        "              \n",
        "        else:\n",
        "\n",
        "          cropped_seq = []\n",
        "          cropped_img = cv2.resize(img_orig[y:h+y, x:w+x],(100,100))\n",
        "          rolling_data[int(ids[i])] = [np.asarray(cropped_img)]  \n",
        "\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "    \n",
        "    if FLAGS.output:\n",
        "      out.write(img)\n",
        "\n",
        "    if cv2.waitKey(1) == ord('q'):\n",
        "      break\n",
        "\n",
        "  cv2.destroyAllWindows()\n",
        "  print('\\nProcessing completed.......!!!')\n",
        "  print('Check video file in Volvo-DataX folder!')\n",
        "  return"
      ],
      "metadata": {
        "id": "ePh-5uUb4mne"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model()"
      ],
      "metadata": {
        "id": "JXeaVg-W5D61"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}